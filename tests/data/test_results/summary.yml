run_suite: ripple
endpoint: hosted_vllm/meta-llama/Llama-3.1-8B-Instruct
total_num_requests: 6
mean_expected_input_tokens: 1540
mean_measured_input_tokens: 1578
relative_input_token_error: 0.02
mean_expected_output_tokens: 32
mean_measured_output_tokens: 32
relative_output_token_error: 0.0
mean_expected_prefix_tokens: 1024
mean_measured_prefix_tokens: 0
relative_prefix_token_error: -1.0
load_results:
- requests_per_second: 1.0
  mean_request_latency: 493.0
  mean_network_latency: 23.0
  percentile_latency:
    p50: 493.0
    p90: 508.2
    p99: 511.62
- requests_per_second: 2.0
  mean_request_latency: 502.0
  mean_network_latency: 32.0
  percentile_latency:
    p50: 494.5
    p90: 540.9
    p99: 553.59
